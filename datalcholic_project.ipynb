{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the analysis\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import gzip\n",
    "import datetime\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset\n",
    "\n",
    "We first define the path to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BA = '../Data/BeerAdvocate_CSV.tar.gz'\n",
    "PATH_RB = '../Data/RateBeer_CSV.tar.gz'\n",
    "folder_BA = tarfile.open(PATH_BA)\n",
    "folder_RB = tarfile.open(PATH_RB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import the dataset and convert the different .csv files to pandas dataframes. This is done on both BeerAdvocate and RateBeer datasets. For each dataset we obtain four dataframes: one for the reviews, one for the beers, one for the breweries and one for the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the files for BeerAdvocate\n",
    "df_beers_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/beers.csv')))\n",
    "df_users_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/users.csv')))\n",
    "df_reviews_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/reviews.csv')))\n",
    "df_breweries_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/breweries.csv')))\n",
    "\n",
    "# Extracting the files for RateBeer\n",
    "df_beers_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/beers.csv')))\n",
    "df_users_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/users.csv')))\n",
    "df_reviews_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/reviews.csv')))\n",
    "df_breweries_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/breweries.csv')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataframes\n",
    "\n",
    "### Adding location information to the dataframes\n",
    "\n",
    "For the review dataframes of both datasets, we want to add two columns that corresponds to the country of the user and the country of the brewery. We do this by extracting the information from the user and brewery dataframes and merging them with the review dataframe. In the end, we obtain `df_RB` and `df_BA` which have the reviews of RateBeer and BeerAdvocate respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RateBeer\n",
    "user_nat_RB=pd.DataFrame()\n",
    "user_nat_RB['user_name']=df_users_RB['user_name']\n",
    "user_nat_RB['location_user']=df_users_RB['location']\n",
    "new_reviews_RB=pd.merge(df_reviews_RB, user_nat_RB,  how='inner', on='user_name')\n",
    "\n",
    "beers_nat_RB=pd.DataFrame()\n",
    "beers_nat_RB['beer_id']=df_breweries_RB['id']\n",
    "beers_nat_RB['beers_location']=df_breweries_RB['location']\n",
    "new_reviews_RB['beer_id']=new_reviews_RB['beer_id'].apply(lambda x: int(x))\n",
    "df_RB= pd.merge(new_reviews_RB, beers_nat_RB, how='inner', on='beer_id')\n",
    "\n",
    "#BeerAdvocate\n",
    "user_nat_BA=pd.DataFrame()\n",
    "user_nat_BA['user_name']=df_users_BA['user_name']\n",
    "user_nat_BA['location_user']=df_users_BA['location']\n",
    "new_reviews_BA=pd.merge(df_reviews_BA, user_nat_BA,  how='inner', on='user_name')\n",
    "\n",
    "beers_nat_BA=pd.DataFrame()\n",
    "beers_nat_BA['beer_id']=df_breweries_BA['id']\n",
    "beers_nat_BA['beers_location']=df_breweries_BA['location']\n",
    "new_reviews_BA['beer_id']=new_reviews_BA['beer_id'].apply(lambda x: int(x))\n",
    "df_BA = pd.merge(new_reviews_BA, beers_nat_BA, how='inner', on='beer_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding states for the US based locations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geographical information contain the name of the country for users and breweries. However, for the US based locations, we also have the name of the state. We want to extract this information and add it to the dataframe. To do so we create will create an extra column for both breweries and users that will contain the US postal abbreviations for each state.\n",
    "\n",
    "We first extract the postal abbreviations for each state from wikipedia using `pd.read_html`. \n",
    "\n",
    "We then process the dataframe into one (`US_states`) containing a column for the postal abbreviations and another one for the corresponding state names. We create from `US_states` two dataframes: `US_states_user` and `US_states_beer`. \n",
    "\n",
    "We add the corresponding postal abbreviation to the user and brewery dataframes. We do this by merging the `df_BA` and `df_RB` dataframes with `US_states_user` and `US_states_beer` respectively. \n",
    "\n",
    "We then finish processing the locations by dropping the state name in the location column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the US_states dataframe\n",
    "US_states = pd.read_html('https://en.wikipedia.org/wiki/ISO_3166-2:US')[0] \n",
    "US_states['Subdivision name (en)'] = US_states['Subdivision name (en)'].apply(lambda x: 'United States, ' + x) \n",
    "US_states['Code'] = US_states['Code'].apply(lambda x: x[3:]) \n",
    "US_states.drop(columns=['Subdivision category'], inplace=True) \n",
    "\n",
    "# Creating the two dataframes from the US_states dataframe\n",
    "US_states_user=US_states.rename(columns={'Subdivision name (en)':'location_user', 'Code':'US_Code_User'}) \n",
    "US_states_beer=US_states.rename(columns={'Subdivision name (en)':'beers_location', 'Code':'US_Code_Beer'}) \n",
    "\n",
    "# Merging to add the postal abbreviations to the RateBeer and BeerAdvocate dataframes\n",
    "df_BA=pd.merge(US_states_beer, df_BA, how='outer', on='beers_location') \n",
    "df_BA=pd.merge(US_states_user, df_BA, how='outer', on='location_user') \n",
    "\n",
    "\n",
    "df_RB=pd.merge(US_states_beer, df_RB, how='outer', on='beers_location')\n",
    "df_RB=pd.merge(US_states_user, df_RB, how='outer', on='location_user')\n",
    "\n",
    "def keep_United_States_if_in_the_string(x): \n",
    "    if 'United States' in x: \n",
    "        return 'United States' \n",
    "    else: \n",
    "        return x \n",
    "\n",
    "# for the location and nationalities we kept only 'United States' and removed the State name after the comma for ploting.\n",
    "\n",
    "df_BA['beers_location']=df_BA['beers_location'].apply(lambda x: str(x)) \n",
    "df_BA['beers_location']=df_BA['beers_location'].apply(lambda x: keep_United_States_if_in_the_string(x)) \n",
    "df_BA['location_user']=df_BA['location_user'].apply(lambda x: str(x)) \n",
    "df_BA['location_user']=df_BA['location_user'].apply(lambda x: keep_United_States_if_in_the_string(x)) \n",
    "\n",
    "df_RB['beers_location']=df_RB['beers_location'].apply(lambda x: str(x))\n",
    "df_RB['beers_location']=df_RB['beers_location'].apply(lambda x: keep_United_States_if_in_the_string(x))\n",
    "df_RB['location_user']=df_RB['location_user'].apply(lambda x: str(x))\n",
    "df_RB['location_user']=df_RB['location_user'].apply(lambda x: keep_United_States_if_in_the_string(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus on the US\n",
    "\n",
    "We want to focus on the US for our analysis. We therefore create two new dataframes `BA_US` and `RB_US` that contain only the reviews of the US based users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US = df_RB[df_RB['location_user'] == 'United States']\n",
    "BA_US = df_BA[df_BA['location_user'] == 'United States']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by checking the number of missing values in each column of the dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US_Code_User           0\n",
       "location_user          0\n",
       "US_Code_Beer      604717\n",
       "beers_location         0\n",
       "beer_name              7\n",
       "beer_id                7\n",
       "brewery_name           7\n",
       "brewery_id             7\n",
       "style                  7\n",
       "abv                25835\n",
       "date                   7\n",
       "user_name              7\n",
       "user_id                7\n",
       "appearance             7\n",
       "aroma                  7\n",
       "palate                 7\n",
       "taste                  7\n",
       "overall                7\n",
       "rating                 7\n",
       "text                  51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB_US.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US_Code_User           0\n",
       "location_user          0\n",
       "US_Code_Beer      331723\n",
       "beers_location         0\n",
       "beer_name              7\n",
       "beer_id                7\n",
       "brewery_name           7\n",
       "brewery_id             7\n",
       "style                  7\n",
       "abv                12991\n",
       "date                   7\n",
       "user_name              8\n",
       "user_id                7\n",
       "appearance          4155\n",
       "aroma               4155\n",
       "palate              4155\n",
       "taste               4155\n",
       "overall             4155\n",
       "rating                 7\n",
       "text                   7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BA_US.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now drop all rows that have NaN values in all the columns `appearance`, `aroma`, `palate`, `taste`, `overall` and `text`. We do this since if there is text then we can use them for the sentiment analysis even if the ratings are missing. And if there is no text but the ratings are present, we can do the other analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US = RB_US.dropna(subset=['appearance', 'aroma', 'palate', 'taste', 'overall', 'text'], how='all')\n",
    "BA_US = BA_US.dropna(subset=['appearance', 'aroma', 'palate', 'taste', 'overall', 'text'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US_Code_User           0\n",
      "location_user          0\n",
      "US_Code_Beer      604710\n",
      "beers_location         0\n",
      "beer_name              0\n",
      "beer_id                0\n",
      "brewery_name           0\n",
      "brewery_id             0\n",
      "style                  0\n",
      "abv                25828\n",
      "date                   0\n",
      "user_name              0\n",
      "user_id                0\n",
      "appearance             0\n",
      "aroma                  0\n",
      "palate                 0\n",
      "taste                  0\n",
      "overall                0\n",
      "rating                 0\n",
      "text                  44\n",
      "dtype: int64\n",
      "Percentage of NaN values in RB_US:  0.005057639852362895 %\n"
     ]
    }
   ],
   "source": [
    "print(RB_US.isnull().sum())\n",
    "print(\"Percentage of NaN values in RB_US: \", (RB_US['text'].isnull().sum()/len(RB_US))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US_Code_User           0\n",
      "location_user          0\n",
      "US_Code_Beer      331716\n",
      "beers_location         0\n",
      "beer_name              0\n",
      "beer_id                0\n",
      "brewery_name           0\n",
      "brewery_id             0\n",
      "style                  0\n",
      "abv                12984\n",
      "date                   0\n",
      "user_name              1\n",
      "user_id                0\n",
      "appearance          4148\n",
      "aroma               4148\n",
      "palate              4148\n",
      "taste               4148\n",
      "overall             4148\n",
      "rating                 0\n",
      "text                   0\n",
      "dtype: int64\n",
      "Percentage of NaN values in BA_US:  0.6316257510834178 %\n"
     ]
    }
   ],
   "source": [
    "print(BA_US.isnull().sum())\n",
    "print(\"Percentage of NaN values in BA_US: \", (BA_US['appearance'].isnull().sum()/len(BA_US))*100, \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our processing, we can see that for `RB_US` we have no NaN values for the rating columns and NaN values for the text column. For `BA_US` we have no NaN values for the text column and NaN values for the rating columns.\n",
    "If we look at how much these NaN values represent in the dataframes, we can see that for `RB_US` the NaN values represent 0.005% of the data and for `BA_US` the NaN values represent 0.6% of the data. Thus we can drop these rows without losing too much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US = RB_US.dropna(subset=['text'], how='all')\n",
    "BA_US = BA_US.dropna(subset=['appearance','aroma','palate','taste','overall'], how='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US_Code_User       object\n",
       "location_user      object\n",
       "US_Code_Beer       object\n",
       "beers_location     object\n",
       "beer_name          object\n",
       "beer_id           float64\n",
       "brewery_name       object\n",
       "brewery_id        float64\n",
       "style              object\n",
       "abv               float64\n",
       "date              float64\n",
       "user_name          object\n",
       "user_id           float64\n",
       "appearance        float64\n",
       "aroma             float64\n",
       "palate            float64\n",
       "taste             float64\n",
       "overall           float64\n",
       "rating            float64\n",
       "text               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB_US.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US_Code_User       object\n",
       "location_user      object\n",
       "US_Code_Beer       object\n",
       "beers_location     object\n",
       "beer_name          object\n",
       "beer_id           float64\n",
       "brewery_name       object\n",
       "brewery_id        float64\n",
       "style              object\n",
       "abv               float64\n",
       "date              float64\n",
       "user_name          object\n",
       "user_id            object\n",
       "appearance        float64\n",
       "aroma             float64\n",
       "palate            float64\n",
       "taste             float64\n",
       "overall           float64\n",
       "rating            float64\n",
       "text               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BA_US.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to convert the `date` column to a datetime object. We do this for both `RB_US` and `BA_US`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US['date'] = RB_US['date'].apply(datetime.datetime.fromtimestamp)\n",
    "BA_US['date'] = BA_US['date'].apply(datetime.datetime.fromtimestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have our two dataframes `RB_US` and `BA_US` that we will use for the analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaee924d214cec0e0c23c8089fbfe4881daa1dd784967d94fcc7b5bc3d329bfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
