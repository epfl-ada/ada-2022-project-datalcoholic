{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the analysis\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Handling datasets ---------- #\n",
    "import os\n",
    "import gzip\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Compute calculations ---------- #\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# ---------- Plots/figures/tables generation libraries ---------- #\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set1\")\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import plotly.tools as tls\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# ---------- Statistical and ML libraries ---------- #\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset\n",
    "\n",
    "We first define the path to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BA = '../Data/BeerAdvocate_CSV.tar.gz'\n",
    "PATH_RB = '../Data/RateBeer_CSV.tar.gz'\n",
    "folder_BA = tarfile.open(PATH_BA)\n",
    "folder_RB = tarfile.open(PATH_RB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import the dataset and convert the different .csv files to pandas dataframes. This is done on both BeerAdvocate and RateBeer datasets. For each dataset we obtain four dataframes: one for the reviews, one for the beers, one for the breweries and one for the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the files for BeerAdvocate\n",
    "df_beers_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/beers.csv')))\n",
    "df_users_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/users.csv')))\n",
    "df_reviews_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/reviews.csv')))\n",
    "df_breweries_BA = pd.read_csv(folder_BA.extractfile(folder_BA.getmember('../Data/BeerAdvocate/breweries.csv')))\n",
    "\n",
    "# Extracting the files for RateBeer\n",
    "df_beers_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/beers.csv')))\n",
    "df_users_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/users.csv')))\n",
    "df_reviews_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/reviews.csv')))\n",
    "df_breweries_RB = pd.read_csv(folder_RB.extractfile(folder_RB.getmember('../Data/RateBeer/breweries.csv')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataframes\n",
    "\n",
    "### Adding location information to the dataframes\n",
    "\n",
    "For the review dataframes of both datasets, we want to add two columns that corresponds to the country of the user and the country of the brewery. We do this by extracting the information from the user and brewery dataframes and merging them with the review dataframe. In the end, we obtain `df_RB` and `df_BA` which have the reviews of RateBeer and BeerAdvocate respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RateBeer\n",
    "user_nat_RB=pd.DataFrame()\n",
    "user_nat_RB['user_name']=df_users_RB['user_name']\n",
    "user_nat_RB['location_user']=df_users_RB['location']\n",
    "new_reviews_RB=pd.merge(df_reviews_RB, user_nat_RB,  how='inner', on='user_name')\n",
    "\n",
    "beers_nat_RB=pd.DataFrame()\n",
    "beers_nat_RB['beer_id']=df_breweries_RB['id']\n",
    "beers_nat_RB['beers_location']=df_breweries_RB['location']\n",
    "new_reviews_RB['beer_id']=new_reviews_RB['beer_id'].apply(lambda x: int(x))\n",
    "df_RB= pd.merge(new_reviews_RB, beers_nat_RB, how='inner', on='beer_id')\n",
    "\n",
    "#BeerAdvocate\n",
    "user_nat_BA=pd.DataFrame()\n",
    "user_nat_BA['user_name']=df_users_BA['user_name']\n",
    "user_nat_BA['location_user']=df_users_BA['location']\n",
    "new_reviews_BA=pd.merge(df_reviews_BA, user_nat_BA,  how='inner', on='user_name')\n",
    "\n",
    "beers_nat_BA=pd.DataFrame()\n",
    "beers_nat_BA['beer_id']=df_breweries_BA['id']\n",
    "beers_nat_BA['beers_location']=df_breweries_BA['location']\n",
    "new_reviews_BA['beer_id']=new_reviews_BA['beer_id'].apply(lambda x: int(x))\n",
    "df_BA = pd.merge(new_reviews_BA, beers_nat_BA, how='inner', on='beer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding states for the US based locations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geographical information contain the name of the country for users and breweries. However, for the US based locations, we also have the name of the state. We want to extract this information and add it to the dataframe. To do so we create will create an extra column for both breweries and users that will contain the US postal abbreviations for each state.\n",
    "\n",
    "We first extract the postal abbreviations for each state from wikipedia using `pd.read_html`. \n",
    "\n",
    "We then process the dataframe into one (`US_states`) containing a column for the postal abbreviations and another one for the corresponding state names. We create from `US_states` two dataframes: `US_states_user` and `US_states_beer`. \n",
    "\n",
    "We add the corresponding postal abbreviation to the user and brewery dataframes. We do this by merging the `df_BA` and `df_RB` dataframes with `US_states_user` and `US_states_beer` respectively. \n",
    "\n",
    "We then finish processing the locations by dropping the state name in the location column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the US_states dataframe\n",
    "US_states = pd.read_html('https://en.wikipedia.org/wiki/ISO_3166-2:US')[0] \n",
    "US_states['Subdivision name (en)'] = US_states['Subdivision name (en)'].apply(lambda x: 'United States, ' + x) \n",
    "US_states['Code'] = US_states['Code'].apply(lambda x: x[3:]) \n",
    "US_states.drop(columns=['Subdivision category'], inplace=True) \n",
    "\n",
    "# Creating the two dataframes from the US_states dataframe\n",
    "US_states_user=US_states.rename(columns={'Subdivision name (en)':'location_user', 'Code':'US_Code_User'}) \n",
    "US_states_beer=US_states.rename(columns={'Subdivision name (en)':'beers_location', 'Code':'US_Code_Beer'}) \n",
    "\n",
    "# Merging to add the postal abbreviations to the RateBeer and BeerAdvocate dataframes\n",
    "df_BA=pd.merge(US_states_beer, df_BA, how='outer', on='beers_location') \n",
    "df_BA=pd.merge(US_states_user, df_BA, how='outer', on='location_user') \n",
    "\n",
    "\n",
    "df_RB=pd.merge(US_states_beer, df_RB, how='outer', on='beers_location')\n",
    "df_RB=pd.merge(US_states_user, df_RB, how='outer', on='location_user')\n",
    "\n",
    "def keep_United_States_if_in_the_string(x): \n",
    "    if 'United States' in x: \n",
    "        return 'United States' \n",
    "    else: \n",
    "        return x \n",
    "\n",
    "# for the location and nationalities we kept only 'United States' and removed the State name after the comma for ploting.\n",
    "\n",
    "df_BA['beers_location']=df_BA['beers_location'].apply(lambda x: str(x)) \n",
    "df_BA['beers_location']=df_BA['beers_location'].apply(lambda x: keep_United_States_if_in_the_string(x)) \n",
    "df_BA['location_user']=df_BA['location_user'].apply(lambda x: str(x)) \n",
    "df_BA['location_user']=df_BA['location_user'].apply(lambda x: keep_United_States_if_in_the_string(x)) \n",
    "\n",
    "df_RB['beers_location']=df_RB['beers_location'].apply(lambda x: str(x))\n",
    "df_RB['beers_location']=df_RB['beers_location'].apply(lambda x: keep_United_States_if_in_the_string(x))\n",
    "df_RB['location_user']=df_RB['location_user'].apply(lambda x: str(x))\n",
    "df_RB['location_user']=df_RB['location_user'].apply(lambda x: keep_United_States_if_in_the_string(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring where users come from\n",
    "\n",
    "In order to better define our analysis, we will first explore the geographical distribution of the users. To do so, we will first create a dataframe containing the number of users per country. We will then plot the distribution of the users on a world map. We do this for both dataframes `df_BA` and `df_RB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_country_users_RB=df_RB.groupby('location_user').count()['user_name'].to_frame().reset_index()\n",
    "count_country_users_RB=count_country_users_RB.rename(columns={'user_name':'count_users'})\n",
    "\n",
    "fig = px.choropleth(count_country_users_RB, \n",
    "                    locations='location_user',  \n",
    "                    locationmode='country names',  \n",
    "                    scope=\"world\", \n",
    "                    color='count_users', \n",
    "                    )\n",
    "fig.update_layout(title_text='RateBeer - Number of users per country') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_country_users_BA=df_BA.groupby('location_user').count()['user_name'].to_frame().reset_index()\n",
    "count_country_users_BA=count_country_users_BA.rename(columns={'user_name':'count_users'})\n",
    "\n",
    "fig = px.choropleth(count_country_users_BA, \n",
    "                    locations='location_user',  \n",
    "                    locationmode='country names',  \n",
    "                    scope=\"world\", \n",
    "                    color='count_users',  \n",
    "                    )\n",
    "fig.update_layout(title_text='BeerAdvocate - Number of users per country') \n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus on the US\n",
    "\n",
    "We want to focus on the US for our analysis. We therefore create two new dataframes `BA_US` and `RB_US` that contain only the reviews of the US based users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US = df_RB[df_RB['location_user'] == 'United States']\n",
    "BA_US = df_BA[df_BA['location_user'] == 'United States']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check if some states have very few reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US['US_Code_User'].value_counts()[RB_US['US_Code_User'].value_counts() < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_US['US_Code_User'].value_counts()[BA_US['US_Code_User'].value_counts() < 1000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the US territories have 1 review each. We will therefore remove them from the dataframe since they will not be useful for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US = RB_US[~RB_US['US_Code_User'].isin(['DC', 'AS', 'GU', 'MP', 'PR', 'VI', 'UM'])]\n",
    "BA_US = BA_US[~BA_US['US_Code_User'].isin(['DC', 'AS', 'GU', 'MP', 'PR', 'VI', 'UM'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore the distribution of the users in the US. We will plot the distribution of the users on a map of the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_state_users_RB=RB_US.groupby('US_Code_User').count()['user_name'].to_frame().reset_index()\n",
    "count_state_users_RB=count_state_users_RB.rename(columns={'user_name':'count_users'})\n",
    "\n",
    "fig = px.choropleth(count_state_users_RB, \n",
    "                    locations='US_Code_User',  \n",
    "                    locationmode='USA-states',  \n",
    "                    scope=\"usa\", \n",
    "                    color='count_users',  \n",
    "                    )\n",
    "fig.update_layout(title_text='RateBeer - Number of users per country') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_state_users_BA=BA_US.groupby('US_Code_User').count()['user_name'].to_frame().reset_index()\n",
    "count_state_users_BA=count_state_users_BA.rename(columns={'user_name':'count_users'})\n",
    "\n",
    "fig = px.choropleth(count_state_users_BA, \n",
    "                    locations='US_Code_User',  \n",
    "                    locationmode='USA-states',  \n",
    "                    scope=\"usa\", \n",
    "                    color='count_users',  \n",
    "                    )\n",
    "fig.update_layout(title_text='BeerAdvocate - Number of users per country') \n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by checking the number of missing values in each column of the dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RB_US.isnull().sum())\n",
    "print(\"Percentage of NaN values in RB_US: \", (RB_US['text'].isnull().sum()/len(RB_US))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BA_US.isnull().sum())\n",
    "print(\"Percentage of NaN values in BA_US: \", (BA_US['appearance'].isnull().sum()/len(BA_US))*100, \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our processing, we can see that for `RB_US` we have no NaN values for the rating columns and NaN values for the text column. For `BA_US` we have no NaN values for the text column and NaN values for the rating columns.\n",
    "If we look at how much these NaN values represent in the dataframes, we can see that for `RB_US` the NaN values represent 0.005% of the data and for `BA_US` the NaN values represent 0.6% of the data. Thus we can drop these rows without losing too much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US = RB_US.dropna(subset=['text'], how='all')\n",
    "BA_US = BA_US.dropna(subset=['appearance','aroma','palate','taste','overall'], how='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_US.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to convert the `date` column to a datetime object. We do this for both `RB_US` and `BA_US`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_US['date'] = RB_US['date'].apply(datetime.datetime.fromtimestamp)\n",
    "BA_US['date'] = BA_US['date'].apply(datetime.datetime.fromtimestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have our two dataframes `RB_US` and `BA_US` that we will use for the analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have as much data as possible for our analysis. We therefore need to merge ratings data from both BeerAdvocate and RateBeer. We need to normalize the data because the distributions are different between the two sites. We follow the same procedure as in Lederrey-West paper ([Lederrey-West_WWW-18](https://dlab.epfl.ch/people/west/pub/Lederrey-West_WWW-18.pdf)):\n",
    "We observe that the mean of the ratings is higher for BeerAdvocate than for Ratebeer. Moreover, when we observe the mean and std of rating over the course of time, *the mean increases, while the standard deviation decreases, from year to year. Assuming that the inherent quality of beers being rated stays roughly constant, the rising mean may be interpreted as score inflation, while the sinking standard deviation could indicate a consolidating consensus about what should constitute the score of an average beer.* (Lederrey-West_WWW-18)\n",
    "\n",
    "Thus we perform a z-score normalization of the ratings : *for each site and each year, we compute the mean and standard deviation over all ratings.We then subtract the mean of year t from all ratings submitted in year t and divide them by the standard deviation of year t , such that each year’s set of ratings has mean 0 and standard deviation 1.* (Lederrey-West_WWW-18)\n",
    "\n",
    "Finally we simply merge the two dataframes into one containings all the raitings from both BeerAdvocate and RateBeer with normalized scores for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    \"\"\"\n",
    "    Normalize the data : compute z scores for each feature (look, smell/aroma, taste, feel/palate, overall & rating)\n",
    "    we do it for each diffrent year to take the temporal drift of the mean and variance into account\n",
    "    \"\"\"\n",
    "    df['year'] = df['date'].apply(lambda x: x.year)\n",
    "    for year in df['year'].unique():\n",
    "        df_year_ = df[df['year'] == year]\n",
    "        df_year = df_year_.copy()\n",
    "        for feature in ['appearance','aroma','taste','palate','overall','rating']:\n",
    "            df_year[feature] = (df_year[feature] - df_year[feature].mean())/df_year[feature].std()\n",
    "        df.loc[df['year'] == year] = df_year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    \"\"\"\n",
    "    Normalize the data : compute z scores for each feature (look, smell/aroma, taste, feel/palate, overall & rating)\n",
    "    we do it for each diffrent year to take the temporal drift of the mean and variance into account\n",
    "    \"\"\"\n",
    "    df['year'] = df['date'].apply(lambda x: x.year)\n",
    "    for year in df['year'].unique():\n",
    "        df_year_ = df[df['year'] == year]\n",
    "        df_year = df_year_.copy()\n",
    "        for feature in ['appearance','aroma','taste','palate','overall','rating']:\n",
    "            df_year[feature] = scale(df_year[feature])\n",
    "        df.loc[df['year'] == year] = df_year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "RB_US_norm = normalize_data(RB_US)\n",
    "BA_US_norm = normalize_data(BA_US)\n",
    "\n",
    "# merge the two dataframes\n",
    "df_ratings = pd.concat([RB_US_norm, BA_US_norm], ignore_index=True)\n",
    "df_ratings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the distribution of the scores for the different features for normalized BeerAdvocate (blue), RateBeer (red) and merged (white) ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 7))\n",
    "sns.histplot(RB_US_norm['appearance'], bins=np.arange(-5, 3, 0.25), ax=ax[0,0], color='red')\n",
    "sns.histplot(BA_US_norm['appearance'], bins=np.arange(-5, 3, 0.25), ax=ax[0,0], color='blue')\n",
    "sns.histplot(df_ratings['appearance'], bins=np.arange(-5, 3, 0.25), ax=ax[0,0], color='white')\n",
    "sns.histplot(RB_US_norm['aroma'], bins=np.arange(-5, 3, 0.25), ax=ax[0,1], color='red')\n",
    "sns.histplot(BA_US_norm['aroma'], bins=np.arange(-5, 3, 0.25), ax=ax[0,1], color='blue')\n",
    "sns.histplot(df_ratings['aroma'], bins=np.arange(-5, 3, 0.25), ax=ax[0,1], color='white')\n",
    "sns.histplot(RB_US_norm['taste'], bins=np.arange(-5, 3, 0.25), ax=ax[0,2], color='red')\n",
    "sns.histplot(BA_US_norm['taste'], bins=np.arange(-5, 3, 0.25), ax=ax[0,2], color='blue')\n",
    "sns.histplot(df_ratings['taste'], bins=np.arange(-5, 3, 0.25), ax=ax[0,2], color='white')\n",
    "sns.histplot(RB_US_norm['palate'], bins=np.arange(-5, 3, 0.25), ax=ax[1,0], color='red')\n",
    "sns.histplot(BA_US_norm['palate'], bins=np.arange(-5, 3, 0.25), ax=ax[1,0], color='blue')\n",
    "sns.histplot(df_ratings['palate'], bins=np.arange(-5, 3, 0.25), ax=ax[1,0], color='white')\n",
    "sns.histplot(RB_US_norm['overall'], bins=np.arange(-5, 3, 0.25), ax=ax[1,1], color='red')\n",
    "sns.histplot(BA_US_norm['overall'], bins=np.arange(-5, 3, 0.25), ax=ax[1,1], color='blue')\n",
    "sns.histplot(df_ratings['overall'], bins=np.arange(-5, 3, 0.25), ax=ax[1,1], color='white')\n",
    "sns.histplot(RB_US_norm['rating'], bins=np.arange(-5, 3, 0.25), ax=ax[1,2], color='red')\n",
    "sns.histplot(BA_US_norm['rating'], bins=np.arange(-5, 3, 0.25), ax=ax[1,2], color='blue')\n",
    "sns.histplot(df_ratings['rating'], bins=np.arange(-5, 3, 0.25), ax=ax[1,2], color='white')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Quick statistics from the data\n",
    "\n",
    "### 1.1 - Number of reviews per brewery\n",
    "First we count the number of reviews made about each brewery. We select only the top10 to display them on a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the breweries with the most reviews\n",
    "brewery_counts = df_ratings['brewery_name'].value_counts().sort_values(ascending=False).head(10)\n",
    "\n",
    "fig = px.bar(brewery_counts, x = brewery_counts.index, y = brewery_counts.values, title = 'Top 10 Breweries with the most reviews',color_discrete_sequence=px.colors.sequential.Plasma)\n",
    "fig.update_layout(\n",
    "    xaxis = dict(title = \"Breweries\"),\n",
    "    yaxis = dict(title = \"Number of reviews\")\n",
    ")\n",
    "fig.show()\n",
    "#comment the code below if you don't want to generate the html\n",
    "#fig.write_html('breweries_reviews.html', include_plotlyjs='cdn', full_html=False, config={'displayModeBar': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Number of reviews per beer\n",
    "Secondly, we count the number of reviews made about each beer. We select only the top10 to display them on a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the beers with the most reviews\n",
    "beers_counts = df_ratings['beer_name'].value_counts().sort_values(ascending=False).head(10)\n",
    "\n",
    "fig = px.bar(beers_counts, x = beers_counts.index, y = beers_counts.values, title = \"Reviews by Beer\",color_discrete_sequence=px.colors.sequential.Plasma)\n",
    "fig.update_layout(\n",
    "    xaxis = dict(title = \"Beer name\"),\n",
    "    yaxis = dict(title = \"Number of reviews\")\n",
    ")\n",
    "fig.show()\n",
    "#comment the code below if you don't want to generate the html\n",
    "#fig.write_html('beer_reviews_BA.html', include_plotlyjs='cdn', full_html=False, config={'displayModeBar': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Number of reviews per state\n",
    "Finaly comes the tricky part, what do we mean by __state__ ?  \n",
    "We count the number of reviews made for each user location (state) using ``US_Code_User`` and we select only the top10 to display them on a barplot.\n",
    "Then count the number of reviews made for each beer location (state) using ``US_Code_Beer`` and we select only the top10 to display them on a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the user locations with the most reviews\n",
    "states_counts = df_ratings['US_Code_User'].value_counts().sort_values(ascending=False).head(10)\n",
    "\n",
    "fig = px.bar(states_counts, x = states_counts.index, y = states_counts.values, title = \"Beer Reviews by State by User\",color_discrete_sequence=px.colors.sequential.Plasma)\n",
    "fig.update_traces(marker_color='#DC3220')\n",
    "fig.update_layout(\n",
    "    xaxis = dict(title = \"States\"),\n",
    "    yaxis = dict(title = \"Number of reviews by User\")\n",
    ")\n",
    "fig.show()\n",
    "#comment the code below if you don't want to generate the html\n",
    "#fig.write_html('states_reviews_users_BA.html', include_plotlyjs='cdn', full_html=False, config={'displayModeBar': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the beer locations with the most reviews\n",
    "states_counts = df_ratings['US_Code_Beer'].value_counts().sort_values(ascending=False).head(10)\n",
    "\n",
    "fig = px.bar(states_counts, x = states_counts.index, y = states_counts.values, title = 'Beer Reviews by State',color_discrete_sequence=px.colors.sequential.Plasma)\n",
    "fig.update_layout(\n",
    "    xaxis = dict(title = \"States\"),\n",
    "    yaxis = dict(title = \"Number of reviews\")\n",
    ")\n",
    "fig.show()\n",
    "#comment the code below if you don't want to generate the html\n",
    "#fig.write_html('states_reviews_beers_BA.html', include_plotlyjs='cdn', full_html=False, config={'displayModeBar': False})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Digging deeper, fine-tuning our analysis\n",
    "### 2.1 - PCA on the rating aspects\n",
    "\n",
    "First we load the necessary dataframes for the analysis. We use the `RB_US` and `BA_US` dataframes that we created in the preprocessing part. We will merge them into one dataframe `data_4_PCA` that we will use for the PCA analysis. We also scale the dataframe to have a mean of 0 and a standard deviation of 1 which is necessary for the PCA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['appearance','aroma','taste','palate']\n",
    "target = 'overall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4_PCA = df_ratings\n",
    "features_PCA = data_4_PCA[features]\n",
    "target_PCA = data_4_PCA[target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then start our PCA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(features_PCA)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component explains 73.2 % of the variance and the second 12.1 % of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pca.transform(features_PCA)\n",
    "scores_df = pd.DataFrame(scores, columns=['PC1', 'PC2'])\n",
    "print(scores_df)\n",
    "loadings = pca.components_.T\n",
    "df_loadings = pd.DataFrame(loadings, columns=['PC1', 'PC2'], index=features)\n",
    "df_loadings.abs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see for the first component, which explains 73.2 % of the variance, the most important feature is taste. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Multiple regression analysis on the rating aspects\n",
    "\n",
    "To perform the multiple regression analysis, we will use the scikit-learn library. We will use the data we prepared in 2.1 : `features_PCA` and `target_PCA`. We use a the LinearRegression model from scikit-learn to fit the model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_PCA, target_PCA, test_size=0.2, random_state=42)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also also want to determine the coefficient of determination $R^2$ of the prediction which will tell us if our model is good or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = regressor.score(X_test, y_test)\n",
    "print(f\"Coefficient of determination: {r2:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the coefficient of determination is 0.75 which is a good value. The data was centered in 2.1 and LinearRegression automatically adds an intercept. Thus the coefficient of determination R^2 is the centered R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = regressor.coef_\n",
    "print(weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally as expected we see that the most important feature is taste. The next most important features are palate and aroma, it seems palate is a bit more important than aroma."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the rating aspects\n",
    "\n",
    "We will explore the correlation between the rating aspects by simply plotting a heatmap of the correlation matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_reg_df = pd.concat([pd.DataFrame(features_PCA), pd.DataFrame(target_PCA)], axis=1)\n",
    "multi_reg_df.columns = [features + ['overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix \n",
    "corr_metrics = multi_reg_df.corr()\n",
    "corr_metrics.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's dig deeper \n",
    "\n",
    "We take a look at 2 beers with low and high scores for taste. We will look at the distribution of the scores for the different features for these two beers.\n",
    "\n",
    "#### Mild taste beers\n",
    "\n",
    "We choose two known beer types for their mild taste : American Adjunct Lager (Budweiser) and Pale Lager. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AALager = df_ratings[features + [target]][df_ratings['style'] =='American Adjunct Lager']\n",
    "AALager_mean = AALager[features + [target]].mean().to_frame()\n",
    "AALager_mean.columns = ['mean']\n",
    "print(AALager_mean)\n",
    "\n",
    "corr_metrics = AALager.corr()\n",
    "corr_metrics.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pale_lager = df_ratings[features + [target]][df_ratings['style'] =='Pale Lager']\n",
    "Pale_lager_mean = Pale_lager[features + [target]].mean().to_frame()\n",
    "Pale_lager_mean.columns = ['mean']\n",
    "print(Pale_lager_mean)\n",
    "\n",
    "corr_metrics = Pale_lager.corr()\n",
    "corr_metrics.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strong taste beers\n",
    "\n",
    "We choose two known beer types for their strong taste : IPA and Stout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa = df_ratings[features + [target]][df_ratings['style'] =='India Pale Ale (IPA)']\n",
    "ipa_mean = ipa[features + [target]].mean().to_frame()\n",
    "ipa_mean.columns = ['mean']\n",
    "print(ipa_mean)\n",
    "\n",
    "corr_metrics = ipa.corr()\n",
    "corr_metrics.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stout = df_ratings[features + [target]][df_ratings['style'] == 'Stout'] \n",
    "stout[features + [target]].mean().to_frame()\n",
    "\n",
    "stout = df_ratings[features + [target]][df_ratings['style'] =='Stout']\n",
    "stout_mean = stout[features + [target]].mean().to_frame()\n",
    "stout_mean.columns = ['mean']\n",
    "print(stout_mean)\n",
    "\n",
    "corr_metrics = stout.corr()\n",
    "corr_metrics.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerstyle_taste = df_ratings[df_ratings['style'].isin(['India Pale Ale (IPA)', 'Stout', 'Pale Lager', 'American Adjunct Lager'])].groupby(['style', 'US_Code_User']).size().reset_index(name='count_users')\n",
    "beerstyle_taste.index = beerstyle_taste['US_Code_User']\n",
    "beerstyle_taste = beerstyle_taste.pivot(columns='style', values='count_users')\n",
    "beerstyle_taste['total'] = beerstyle_taste.sum(axis=1)\n",
    "beerstyle_taste.reset_index(inplace=True)\n",
    "fig = px.choropleth(beerstyle_taste, \n",
    "                    locations='US_Code_User',  \n",
    "                    locationmode='USA-states',  \n",
    "                    scope=\"usa\", \n",
    "                    color='total',\n",
    "                    hover_data=['India Pale Ale (IPA)', 'Stout', 'Pale Lager', 'American Adjunct Lager'],\n",
    "                    )\n",
    "fig.update_layout(title_text='RateBeer - Number of users per country') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerstyle_taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    beerstyle_taste,\n",
    "    locationmode='USA-states',  \n",
    "    scope=\"usa\",\n",
    "    locations=\"US_Code_User\", \n",
    "    color=\"total\", \n",
    ")\n",
    "\n",
    "# Add a dropdown menu\n",
    "updatemenus = list([\n",
    "    dict(\n",
    "        buttons=list([\n",
    "            dict(\n",
    "                label=\"Total\",\n",
    "                args=[{\"color\": \"total\"}, {\"title\": \"total\"}],\n",
    "                method=\"update\",\n",
    "            ),\n",
    "            dict(\n",
    "                label=\"American Adjunct Lager\",\n",
    "                args=[{\"color\": \"American Adjunct Lager\"}, {\"title\": \"American Adjunct Lager\"}],\n",
    "                method=\"update\",\n",
    "            ),\n",
    "            dict(\n",
    "                label=\"Pale Lager\",\n",
    "                args=[{\"color\": \"Pale Lager\"}, {\"title\": \"Pale Lager\"}],\n",
    "                method=\"update\",\n",
    "            ),\n",
    "            dict(\n",
    "                label=\"India Pale Ale (IPA)\",\n",
    "                args=[{\"color\": \"India Pale Ale (IPA)\"}, {\"title\": \"India Pale Ale (IPA)\"}],\n",
    "                method=\"update\",\n",
    "            ),\n",
    "            dict(\n",
    "                label=\"Stout\",\n",
    "                args=[{\"color\": \"Stout\"}, {\"title\": \"Stout\"}],\n",
    "                method=\"update\",\n",
    "            ),\n",
    "        ]),\n",
    "        direction = 'down',\n",
    "        pad = {'r': 10, 't': 10},\n",
    "        showactive = False,\n",
    "        x = 0.1,\n",
    "        xanchor = 'left',\n",
    "        y = 1.1,\n",
    "        yanchor = 'top' \n",
    "    ),\n",
    "])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Sentiment analysis\n",
    "\n",
    "First step is to run the analysis over the whole dataframe ``df_ratings``, as it is a memory intensive task, we will chunk the dataframe into smaller dataframes of 200000 rows each. We will then run the analysis on each chunk and store the results in a new file ``df_sentiment.csv``. We will then load the results from this file and continue the analysis.  \n",
    "Using the TextBlob library we compute 2 scores : sentiment and objectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 200000\n",
    "start_row = 0\n",
    "end_row = start_row + chunk_size\n",
    "df_sentiment = df_ratings\n",
    "\n",
    "while start_row < len(df_sentiment):\n",
    "  df_chunk = df_sentiment.iloc[start_row:end_row]\n",
    "  df_chunk['sentiment'] = df_chunk['text'].apply(lambda x: TextBlob(str(x)).sentiment[0])\n",
    "  df_chunk['objectivity'] = df_chunk['text'].apply(lambda x: TextBlob(str(x)).sentiment[1])\n",
    "  #Write the chunk of data into a file\n",
    "  df_chunk.to_csv('/content/drive/MyDrive/ada-2022-projet-datalcoholic/df_sentiment.csv', index=False, mode='a')\n",
    "  df_chunk.drop(df_chunk.index, inplace=True)\n",
    "  #Update counters\n",
    "  start_row += chunk_size\n",
    "  end_row += chunk_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some processing to get the best out of this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = df_sentiment[df_sentiment['sentiment'] != 'sentiment'] #error when chucking the data\n",
    "df_sentiment.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df_sentiment.dropna()\n",
    "df_sentiment['sentiment'] = df_sentiment['sentiment'].apply(lambda x : float(x))\n",
    "df_sentiment['rating'] = df_sentiment['rating'].apply(lambda x : float(x))\n",
    "df_sentiment['year'] = df_sentiment['year'].apply(lambda x : float(x)) # convert year to float for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment.to_csv('../Data/df_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = pd.read_csv('../Data/df_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Sentiment analysis and Rating distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As users are asked to grade the beer and give a textual review, let's investigate if these two are correlated. We will first do a simple comparison through a boxplot of the sentiment score and the rating score for the top10 beers having the most reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10 = df_sentiment['beer_name'].value_counts().sort_values(ascending=False).head(10).reset_index()\n",
    "df_top10_stats = df_sentiment[df_sentiment['beer_name'].isin(df_top10['beer_name'])].reset_index()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y=df_top10_stats['sentiment'], x=df_top10_stats['beer_name'], name='Sentiment score', boxpoints=False, marker_color='#10128F'))\n",
    "fig.add_trace(go.Box(y=df_top10_stats['rating'], x=df_top10_stats['beer_name'], name='Rating score', boxpoints=False, marker_color='#E83101'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Sentiment vs Rating\",\n",
    "    xaxis_title=\"Top 10 Most reviewed Beers\",\n",
    "    yaxis_title=\"Sentiment Score and rating distributions\",\n",
    "    boxmode='group' # group together boxes of the different traces for each value of x\n",
    ")\n",
    "fig.show()\n",
    "#comment the code below if you don't want to generate the html\n",
    "#fig.write_html('boxplot_sentiment_rating.html', include_plotlyjs='cdn', full_html=False, config={'displayModeBar': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the distribution of the sentiment score next to the distribution of the rating score do not really give us informations about a possible correlation between the two. One observation we can made is that the rating scores are way more spread around the median than the sentiment scores. It can be interesting to make a regression between these two variables to see if there is a linear correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Linear regression\n",
    "\n",
    "We will use the ``scikit-learn`` library to perform the linear regression and the ``LinearRegression`` model to fit the model on the data.  \n",
    "We chose to do it for 3 of the top 10 beers as well as 3 random beers having at least 1000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- Bud Light ---------#\n",
    "df_BL = df_sentiment[df_sentiment['beer_name'] == 'Bud Light']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "regression_BL = df_BL[['rating', 'sentiment']]\n",
    "scaled_data = scaler.fit_transform(regression_BL)\n",
    "\n",
    "df_scaled_BL = pd.DataFrame(scaled_data, columns=regression_BL.columns)\n",
    "x = np.array(df_scaled_BL['rating']).reshape(-1, 1)\n",
    "y = np.array(df_scaled_BL['sentiment'])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x, y)\n",
    "predicted_BL = model.predict(x)\n",
    "r2_BL = r2_score(df_scaled_BL['sentiment'], predicted_BL) #r2 score\n",
    "\n",
    "\n",
    "#--------- Newcastle Brown Ale ---------#\n",
    "df_NBA = df_sentiment[df_sentiment['beer_name'] == 'Newcastle Brown Ale']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "regression_NBA = df_NBA[['rating', 'sentiment']]\n",
    "scaled_data = scaler.fit_transform(regression_NBA)\n",
    "\n",
    "df_scaled_NBA = pd.DataFrame(scaled_data, columns=regression_NBA.columns)\n",
    "x = np.array(df_scaled_NBA['rating']).reshape(-1, 1)\n",
    "y = np.array(df_scaled_NBA['sentiment'])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x, y)\n",
    "predicted_NBA = model.predict(x)\n",
    "r2_NBA = r2_score(df_scaled_NBA['sentiment'], predicted_NBA) #r2 score\n",
    "\n",
    "\n",
    "#--------- Brooklyn Black Chocolate Stout ---------#\n",
    "df_BBC = df_sentiment[df_sentiment['beer_name'] == 'Brooklyn Black Chocolate Stout']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "regression_BBC = df_BBC[['rating', 'sentiment']]\n",
    "scaled_data = scaler.fit_transform(regression_BBC)\n",
    "\n",
    "df_scaled_BBC = pd.DataFrame(scaled_data, columns=regression_BBC.columns)\n",
    "x = np.array(df_scaled_BBC['rating']).reshape(-1, 1)\n",
    "y = np.array(df_scaled_BBC['sentiment'])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x, y)\n",
    "predicted_BBC = model.predict(x)\n",
    "r2_BBC = r2_score(df_scaled_BBC['sentiment'], predicted_BBC) #r2 score\n",
    "\n",
    "\n",
    "#--------- Tuppers Hop Pocket Ale ---------#\n",
    "df_THPA = df_sentiment[df_sentiment['beer_name'] == 'Tuppers Hop Pocket Ale']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "regression_THPA = df_THPA[['rating', 'sentiment']]\n",
    "scaled_data = scaler.fit_transform(regression_THPA)\n",
    "\n",
    "df_scaled_THPA = pd.DataFrame(scaled_data, columns=regression_THPA.columns)\n",
    "x = np.array(df_scaled_THPA['rating']).reshape(-1, 1)\n",
    "y = np.array(df_scaled_THPA['sentiment'])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x, y)\n",
    "predicted_THPA = model.predict(x)\n",
    "r2_THPA = r2_score(df_scaled_THPA['sentiment'], predicted_THPA) #r2 score\n",
    "\n",
    "\n",
    "#--------- Great Lakes Oktoberfest ---------#\n",
    "df_GLO = df_sentiment[df_sentiment['beer_name'] == 'Great Lakes Oktoberfest']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "regression_GLO = df_GLO[['rating', 'sentiment']]\n",
    "scaled_data = scaler.fit_transform(regression_GLO)\n",
    "\n",
    "df_scaled_GLO = pd.DataFrame(scaled_data, columns=regression_GLO.columns)\n",
    "x = np.array(df_scaled_GLO['rating']).reshape(-1, 1)\n",
    "y = np.array(df_scaled_GLO['sentiment'])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x, y)\n",
    "predicted_GLO = model.predict(x)\n",
    "r2_GLO = r2_score(df_scaled_GLO['sentiment'], predicted_GLO) #r2 score\n",
    "\n",
    "\n",
    "#--------- St-Feuillien Triple ---------#\n",
    "df_SFT = df_sentiment[df_sentiment['beer_name'] == 'St-Feuillien Triple']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "regression_SFT = df_SFT[['rating', 'sentiment']]\n",
    "scaled_data = scaler.fit_transform(regression_SFT)\n",
    "\n",
    "df_scaled_SFT = pd.DataFrame(scaled_data, columns=regression_SFT.columns)\n",
    "x = np.array(df_scaled_SFT['rating']).reshape(-1, 1)\n",
    "y = np.array(df_scaled_SFT['sentiment'])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x, y)\n",
    "predicted_SFT = model.predict(x)\n",
    "r2_SFT = r2_score(df_scaled_SFT['sentiment'], predicted_SFT) #r2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate 2 plots having each 3 subplots in one column to facilitate the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=3, cols=1, \n",
    "    subplot_titles=(\"Bud Light\", 'Newcastle Brown Ale', 'Brooklyn Black Chocolate Stout'),\n",
    "    shared_xaxes=True,\n",
    "    x_title='Rating',\n",
    "    y_title='Sentiment Score',\n",
    "    vertical_spacing = 0.04)\n",
    "\n",
    "#BL\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_BL['rating'], \n",
    "    y=df_scaled_BL['sentiment'], \n",
    "    mode='markers', marker_color = '#8B9EF8'),\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_BL['rating'], \n",
    "    y=predicted_BL, \n",
    "    mode='lines', marker_color = '#F31E18'), \n",
    "    row=1, col=1)\n",
    "\n",
    "#NBA\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_NBA['rating'], \n",
    "    y=df_scaled_NBA['sentiment'], \n",
    "    mode='markers', marker_color = '#8B9EF8'),\n",
    "    row=2, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_NBA['rating'], \n",
    "    y=predicted_NBA, \n",
    "    mode='lines', marker_color = '#F31E18'), \n",
    "    row=2, col=1)\n",
    "\n",
    "#BBC\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_BBC['rating'], \n",
    "    y=df_scaled_BBC['sentiment'], \n",
    "    mode='markers', marker_color = '#8B9EF8'),\n",
    "    row=3, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_BBC['rating'], \n",
    "    y=predicted_BBC, \n",
    "    mode='lines', marker_color = '#F31E18'), \n",
    "    row=3, col=1)\n",
    "\n",
    "fig.update_traces(marker={'size': 3}, showlegend=False)\n",
    "fig.update_xaxes(range=[-4,4])\n",
    "fig.update_yaxes(range=[-5,5])\n",
    "fig.update_layout(height=650, width=500)\n",
    "fig.add_annotation(x=-3,y=4,xref='x1',yref='y1',\n",
    "                   text=\"R² =\" + str(round(r2_BL,3-int(math.floor(math.log10(abs(r2_BL))))-1)),\n",
    "                   showarrow=False, row=1, col=1)\n",
    "fig.add_annotation(x=-3,y=4,xref='x2',yref='y2',\n",
    "                   text=\"R² =\" + str(round(r2_NBA,3-int(math.floor(math.log10(abs(r2_NBA))))-1)),\n",
    "                   showarrow=False, row=2, col=1)\n",
    "fig.add_annotation(x=-3,y=4,xref='x3',yref='y3',\n",
    "                   text=\"R² =\" + str(round(r2_BBC,3-int(math.floor(math.log10(abs(r2_BBC))))-1)),\n",
    "                   showarrow=False, row=3, col=1)\n",
    "fig.show()\n",
    "#comment the code below if you don't want to generate the html\n",
    "#fig.write_html('regression_1.html', include_plotlyjs='cdn', full_html=False, config={'displayModeBar': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=3, cols=1, \n",
    "    subplot_titles=(\"uppers Hop Pocket Ale\", 'Great Lakes Oktoberfest', 'St-Feuillien Triple'),\n",
    "    shared_xaxes=True,\n",
    "    x_title='Rating',\n",
    "    y_title='Sentiment Score',\n",
    "    vertical_spacing = 0.04)\n",
    "\n",
    "#THPA\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_THPA['rating'], \n",
    "    y=df_scaled_THPA['sentiment'], \n",
    "    mode='markers', marker_color = '#8B9EF8'),\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_THPA['rating'], \n",
    "    y=predicted_THPA, \n",
    "    mode='lines', marker_color = '#F31E18'), \n",
    "    row=1, col=1)\n",
    "\n",
    "#GLO\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_GLO['rating'], \n",
    "    y=df_scaled_GLO['sentiment'], \n",
    "    mode='markers', marker_color = '#8B9EF8'),\n",
    "    row=2, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_GLO['rating'], \n",
    "    y=predicted_GLO, \n",
    "    mode='lines', marker_color = '#F31E18'), \n",
    "    row=2, col=1)\n",
    "\n",
    "#SFT\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_SFT['rating'], \n",
    "    y=df_scaled_SFT['sentiment'], \n",
    "    mode='markers', marker_color = '#8B9EF8'),\n",
    "    row=3, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=df_scaled_SFT['rating'], \n",
    "    y=predicted_SFT, \n",
    "    mode='lines', marker_color = '#F31E18'), \n",
    "    row=3, col=1)\n",
    "\n",
    "fig.update_traces(marker={'size': 3}, showlegend=False)\n",
    "fig.update_xaxes(range=[-4,4])\n",
    "fig.update_yaxes(range=[-5,5])\n",
    "fig.update_layout(height=650, width=500)\n",
    "fig.add_annotation(x=-3,y=4,xref='x1',yref='y1',\n",
    "                   text=\"R² =\" + str(round(r2_THPA,3-int(math.floor(math.log10(abs(r2_THPA))))-1)),\n",
    "                   showarrow=False, row=1, col=1)\n",
    "fig.add_annotation(x=-3,y=4,xref='x2',yref='y2',\n",
    "                   text=\"R² =\" + str(round(r2_GLO,3-int(math.floor(math.log10(abs(r2_GLO))))-1)),\n",
    "                   showarrow=False, row=2, col=1)\n",
    "fig.add_annotation(x=-3,y=4,xref='x3',yref='y3',\n",
    "                   text=\"R² =\" + str(round(r2_SFT,3-int(math.floor(math.log10(abs(r2_SFT))))-1)),\n",
    "                   showarrow=False, row=3, col=1)\n",
    "fig.show()\n",
    "#comment the code below if you don't want to generate the html\n",
    "#fig.write_html('regression_2.html', include_plotlyjs='cdn', full_html=False, config={'displayModeBar': False})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_notnormalized = pd.concat([RB_US, BA_US], ignore_index=True)\n",
    "#create dataframe with mean overall rating over time using a monthly frequency\n",
    "df_ratings['date'] = pd.to_datetime(df_ratings_notnormalized['date'])\n",
    "df_ratings = df_ratings.set_index('date')\n",
    "df_ratings = df_ratings.resample('M').mean()\n",
    "df_ratings = df_ratings.reset_index()\n",
    "df_ratings = df_ratings.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the mean overall rating over time\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ax.plot(df_ratings['date'], df_ratings['overall'], color='blue')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Mean Overall Rating')\n",
    "ax.set_title('Mean Overall Rating Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open csv file called 'results_by_state_V2.csv' and read it into a dataframe\n",
    "df_state = pd.read_csv('results_by_state_V2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WV_evolution= df_state[df_state['State'] == 'WV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_notnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WV_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WV_reviews = df_ratings_notnormalized[df_ratings_notnormalized['US_Code_User'] == 'WV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WV_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of reviews over time \n",
    "number_of_reviews_WV = WV_reviews.groupby('year').count()\n",
    "number_of_reviews_WV "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaee924d214cec0e0c23c8089fbfe4881daa1dd784967d94fcc7b5bc3d329bfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
